import os
import argparse

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from exp_name_utils import augment_df

CLUSTERS = ["small", "mid"]
MODELS = ["GPT", "T5"]

parser = argparse.ArgumentParser()
parser.add_argument('--best_throughput_data', type=str, required=True,
                    help="Path to the jsonl file containing the best "
                    "throughput data, generated by gather_throughput_stats.py")
parser.add_argument('--controlled_throughput_data', type=str, required=True,
                    help="Path to the jsonl file containing the controlled "
                    "throughput data, generated by gather_throughput_stats.py")
parser.add_argument('--out_dir', type=str, required=True,
                    help="Path to the directory where the output plots "
                    "will be saved")

args = parser.parse_args()

if not os.path.exists(args.out_dir):
    os.makedirs(args.out_dir)

df = pd.read_json(args.best_throughput_data, lines=True)
df_c = pd.read_json(args.controlled_throughput_data, lines=True)

df = pd.concat([df, df_c], ignore_index=True)

df = augment_df(df)

def calculate_throughput(row):
    num_tokens = row["num_tokens"]
    num_iters = row["num_iters"]
    total_time = row["avg_iter_time"] * num_iters # time is in ms
    return (num_tokens / total_time) * 1000

df["throughput"] = df.apply(calculate_throughput, axis=1)

# some global constants for plotting
FIG12_GLOBAL_BATCH_SIZE = 65536
FIG13_SEQLEN = 2048
HUE_ORDER = ["baseline (c)", "baseline", "dynapipe"]
PALETTE = sns.color_palette()
HATCHES = ['//', 'xx', '--', '..']

# function to draw a cross in the bar plot for missing data (e.g., OOM)
def add_cross_at(ax: plt.Axes, x_index, hue, size=80, y_offset=500):
    # x_index is the index of the bar (excluding hue)
    hue_index = HUE_ORDER.index(hue)
    hue_offset = (-(len(HUE_ORDER) / 2) + 0.5 + hue_index) * ax.patches[0].get_width()
    ax.scatter(x_index + hue_offset, y_offset, marker='x', color='red', s=size)

def draw_fig12(df, ouput_prefix):
    # Fig 12: fix global batch size, vary sequence length
    fig12_df = df[(df['global_batch_size'] == FIG12_GLOBAL_BATCH_SIZE)]
    seqlen_range = sorted(fig12_df["seqlen"].unique())

    fig, ax = plt.subplots(1, 1, figsize=(5, 3))

    sns.barplot(x='seqlen', y='throughput', hue='framework', data=fig12_df, ax=ax, orient='v', hue_order=HUE_ORDER, palette=PALETTE)

    # draw crosses for missing data
    y_offset = ax.get_ylim()[1] * 0.04
    size = 150
    for seqlen in seqlen_range[:len(ax.get_xticklabels())]:
        x_index = seqlen_range.index(seqlen)
        for hue in HUE_ORDER:
            if len(fig12_df[(fig12_df["seqlen"] == seqlen) & (fig12_df["framework"] == hue)]) == 0:
                add_cross_at(ax, x_index, hue, y_offset=y_offset, size=size)

    unique_patch_colors = []
    for i, bar in enumerate(ax.patches):
        if bar.get_facecolor() not in unique_patch_colors:
            unique_patch_colors.append(bar.get_facecolor())

    plt.rcParams['hatch.linewidth'] = 0.3
    for i, bar in enumerate(ax.patches):
        color_idx = unique_patch_colors.index(bar.get_facecolor())
        hatch = HATCHES[color_idx]
        bar.set_hatch(hatch)
        bar.set_edgecolor('white')

    ax.set_ylabel("Throughput (Tokens/s)")
    ax.set_xlabel("Max Sequence Length")

    l = ax.legend(loc='lower center', ncols=4, bbox_to_anchor=(0.5, 1), prop={'size': 9}, columnspacing=0.8)
    l.get_texts()[0].set_text("MLM+DS (C)")
    l.get_texts()[1].set_text("MLM+DS")
    l.get_texts()[2].set_text("DynaPipe")

    plt.savefig(ouput_prefix + f".pdf", bbox_inches='tight')

def draw_fig13(df, ouput_prefix):
    # Fig 13: fix sequence length, vary global batch size
    fig13_df = df[(df['seqlen'] == FIG13_SEQLEN)]
    gbs_range = sorted(fig13_df["global_batch_size"].unique())

    fig, ax = plt.subplots(1, 1, figsize=(5, 3))

    # ax.set_title(f'Max Sequence Length: {gbs_range_seqlen}')
    sns.barplot(x='global_batch_size', y='throughput', hue='framework', data=fig13_df, ax=ax, orient='v', hue_order=HUE_ORDER, palette=PALETTE)

    # draw crosses for missing data
    y_offset = ax.get_ylim()[1] * 0.04
    size = 150
    for gbs in gbs_range:
        x_index = gbs_range.index(gbs)
        for hue in HUE_ORDER:
            if len(fig13_df[(fig13_df["global_batch_size"] == gbs) & (fig13_df["framework"] == hue)]) == 0:
                add_cross_at(ax, x_index, hue, y_offset=y_offset, size=size)

    unique_patch_colors = []
    for i, bar in enumerate(ax.patches):
        if bar.get_facecolor() not in unique_patch_colors:
            unique_patch_colors.append(bar.get_facecolor())

    plt.rcParams['hatch.linewidth'] = 0.3
    for i, bar in enumerate(ax.patches):
        color_idx = unique_patch_colors.index(bar.get_facecolor())
        hatch = HATCHES[color_idx]
        bar.set_hatch(hatch)
        bar.set_edgecolor('white')

    ax.set_ylabel("Throughput (Tokens/s)")
    ax.set_xlabel("Global Batch Size")

    l = ax.legend(loc='lower center', ncols=4, bbox_to_anchor=(0.5, 1), prop={'size': 9}, columnspacing=0.8)
    l.get_texts()[0].set_text("MLM+DS (C)")
    l.get_texts()[1].set_text("MLM+DS")
    l.get_texts()[2].set_text("DynaPipe")

    plt.savefig(ouput_prefix + f".pdf", bbox_inches='tight')



FIG_INDEX_DICT = {
    ("GPT", "small"): "a",
    ("GPT", "mid"): "b",
    ("T5", "small"): "e",
    ("T5", "mid"): "f"
}

for cluster in CLUSTERS:
    for model in MODELS:
        filtered_df = df[(df["cluster"] == cluster) & (df["model"] == model)]
        fig12_out_prefix = os.path.join(args.out_dir, "fig12_" + FIG_INDEX_DICT[(model, cluster)])
        draw_fig12(filtered_df, fig12_out_prefix)
        fig13_out_prefix = os.path.join(args.out_dir, "fig13_" + FIG_INDEX_DICT[(model, cluster)])
        draw_fig13(filtered_df, fig13_out_prefix)