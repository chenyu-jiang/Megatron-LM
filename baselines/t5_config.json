{
    "model_name_or_path": "t5-11b",
    "output_dir": "t5-11b-output",

    "data_path": "/root/Megatron-LM/datasets/cleaned_supervised_proportional_inputs_document",
    "target_data_path": "/root/Megatron-LM/datasets/cleaned_supervised_proportional_targets_document",
    "vocab_file": "/root/t5-base-vocab.txt",
    "global_batch_size": 16384,
    "max_source_length": 1024,
    "max_target_length": 1024,

    "do_train": true,
    "per_device_train_batch_size": 8,
    "gradient_accumulation_steps": 1,
    "num_train_epochs": 1,
    "max_steps": 500,
    "save_strategy": "no",
    "fp16": true,
    "dataloader_num_workers": 2,
    "remove_unused_columns": false
}