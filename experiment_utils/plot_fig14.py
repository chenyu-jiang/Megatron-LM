import argparse

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from exp_name_utils import augment_df

CLUSTER = "mid"
MODELS = ["GPT", "T5"]

parser = argparse.ArgumentParser()
parser.add_argument('--batch_eff_data', type=str, required=True,
                    help="Path to the jsonl file containing the batching efficiency "
                    "data, generated by collect_batching_efficiency_stats.py")
parser.add_argument('--out_dir', type=str, required=True,
                    help="Path to the directory where the output plots "
                    "will be saved")

args = parser.parse_args()

if not os.path.exists(args.out_dir):
    os.makedirs(args.out_dir)

df = pd.read_json(args.batch_eff_data, lines=True)
df = augment_df(df)

def calc_enc_eff(row):
    if np.isnan(row["enc_eff"]):
        return row["enc_tokens"] / row["enc_padded_tokens"]
    else:
        return row["enc_eff"]

def calc_dec_eff(row):
    if np.isnan(row["dec_eff"]):
        if row["dec_tokens"] == 0.0:
            return 0
        return row["dec_tokens"] / row["dec_paddded_tokens"]
    else:
        return row["dec_eff"]

df["enc_eff"] = df.apply(calc_enc_eff, axis=1)
df["dec_eff"] = df.apply(calc_dec_eff, axis=1)

df = df[(df["model"].isin(MODELS)) & (df["cluster"] == CLUSTER)]

df = df.rename(columns={'enc_eff': 'Batching Efficiency-Encoder', "dec_eff": 'Batching Efficiency-Decoder'}).reset_index()
df["id"] = df.index
df = pd.wide_to_long(df, stubnames=['Batching Efficiency'], i="id", j='Type', sep='-', suffix="\D+").reset_index()

# plot left figure (fix global batch size, vary seqlen)
FIG14_LEFT_GBS = 65536
for model in MODELS:
    model_df = df[(df["model"] == model) & (df["global_batch_size"] == FIG14_LEFT_GBS)].copy()
    if model == "GPT":
        model_df = model_df[model_df["Type"] == "Encoder"]
        for row in model_df.itertuples():
            model_df.at[row.Index, "Type"] = row.framework
    else:
        for row in model_df.itertuples():
            model_df.at[row.Index, "Type"] = row.framework + " (" + row.Type + ")"

    model_df = model_df[model_df["Batching Efficiency"].notna()]

    hue_order = ["baseline", "dynapipe"] if model == "GPT" else ["baseline (Encoder)", "baseline (Decoder)", "dynapipe (Encoder)", "dynapipe (Decoder)"]

    palette = sns.color_palette() if model == "GPT" else sns.color_palette("Paired", 6)
    hatches = ['//', 'xx', '--', '..', "||", "++"]
    seqlen_range = sorted(model_df["seqlen"].unique())
    def add_cross_at(ax: plt.Axes, x, hue, size=80, y_offset=500):
        x_index = seqlen_range.index(x)
        hue_index = hue_order.index(hue)
        hue_offset = (-(len(hue_order) / 2) + 0.5 + hue_index) * ax.patches[0].get_width()
        ax.scatter(x_index + hue_offset, y_offset, marker='x', color='red', s=size)

    fig, ax = plt.subplots(1, 1, figsize=(5, 3))
    hue_key = "framework" if model == "GPT" else "Type"
    sns.barplot(x='seqlen', y='Batching Efficiency', hue=hue_key, data=model_df, ax=ax, orient='v', hue_order=hue_order, palette=palette)

    # draw crosses for missing data
    for seqlen in seqlen_range[:len(ax.get_xticklabels())]:
        for hue in hue_order:
            if len(model_df[(model_df["seqlen"] == seqlen) & (model_df[hue_key] == hue)]) == 0:
                add_cross_at(ax, seqlen, hue, y_offset=0.03, size=60)

    unique_patch_colors = []
    for i, bar in enumerate(ax.patches):
        if bar.get_facecolor() not in unique_patch_colors:
            unique_patch_colors.append(bar.get_facecolor())

    plt.rcParams['hatch.linewidth'] = 0.3
    for i, bar in enumerate(ax.patches):
        color_idx = unique_patch_colors.index(bar.get_facecolor())
        hatch = hatches[color_idx]
        bar.set_hatch(hatch)
        bar.set_edgecolor('white')

    ax.set_ylabel("Batching Efficiency")
    ax.set_xlabel("Max Sequence Length")

    l = ax.legend(loc='lower center', ncols=2, bbox_to_anchor=(0.5, 1), prop={'size': 9}, columnspacing=0.8)
    if model == "GPT":
        l.get_texts()[0].set_text("MLM+DS")
        l.get_texts()[1].set_text("DynaPipe")
    else:
        l.get_texts()[0].set_text("MLM+DS (Encoder)")
        l.get_texts()[1].set_text("MLM+DS (Decoder)")
        l.get_texts()[2].set_text("DynaPipe (Encoder)")
        l.get_texts()[3].set_text("DynaPipe (Decoder)")

    for item in (ax.get_xticklabels() + ax.get_yticklabels()):
        item.set_fontsize(12)
    for item in [ax.title, ax.xaxis.label, ax.yaxis.label]:
        item.set_fontsize(12)
    plt.setp(ax.get_legend().get_texts(), fontsize='12') # for legend text
    plt.setp(ax.get_legend().get_title(), fontsize='12') # for legend title

    subfig = "a" if model == "GPT" else "b"
    plt.savefig(os.path.join(args.out_dir, f"fig14_{subfig}_left.pdf"), bbox_inches='tight')


# plot right figure (fix seqlen, vary global batch size)
FIG14_RIGHT_SEQLEN = 2048
for model in MODELS:
    model_df = df[(df["model"] == model) & (df["seqlen"] == FIG14_RIGHT_SEQLEN)].copy()
    if model == "GPT":
        model_df = model_df[model_df["Type"] == "Encoder"]
        for row in model_df.itertuples():
            model_df.at[row.Index, "Type"] = row.framework
    else:
        for row in model_df.itertuples():
            model_df.at[row.Index, "Type"] = row.framework + " (" + row.Type + ")"

    model_df = model_df[model_df["Batching Efficiency"].notna()]

    hue_order = ["baseline", "dynapipe"] if model == "GPT" else ["baseline (Encoder)", "baseline (Decoder)", "dynapipe (Encoder)", "dynapipe (Decoder)"]

    palette = sns.color_palette() if model == "GPT" else sns.color_palette("Paired", 6)
    hatches = ['//', 'xx', '--', '..', "||", "++"]
    gbs_range = sorted(model_df["global_batch_size"].unique())
    def add_cross_at(ax: plt.Axes, x, hue, size=80, y_offset=500):
        x_index = gbs_range.index(x)
        hue_index = hue_order.index(hue)
        hue_offset = (-(len(hue_order) / 2) + 0.5 + hue_index) * ax.patches[0].get_width()
        ax.scatter(x_index + hue_offset, y_offset, marker='x', color='red', s=size)

    fig, ax = plt.subplots(1, 1, figsize=(5, 3))
    hue_key = "framework" if model == "GPT" else "Type"
    sns.barplot(x='global_batch_size', y='Batching Efficiency', hue=hue_key, data=model_df, ax=ax, orient='v', hue_order=hue_order, palette=palette)

    # draw crosses for missing data
    for gbs in gbs_range[:len(ax.get_xticklabels())]:
        for hue in hue_order:
            if len(model_df[(model_df["global_batch_size"] == gbs) & (model_df[hue_key] == hue)]) == 0:
                add_cross_at(ax, gbs, hue, y_offset=0.03, size=60)

    unique_patch_colors = []
    for i, bar in enumerate(ax.patches):
        if bar.get_facecolor() not in unique_patch_colors:
            unique_patch_colors.append(bar.get_facecolor())

    plt.rcParams['hatch.linewidth'] = 0.3
    for i, bar in enumerate(ax.patches):
        color_idx = unique_patch_colors.index(bar.get_facecolor())
        hatch = hatches[color_idx]
        bar.set_hatch(hatch)
        bar.set_edgecolor('white')

    ax.set_ylabel("Batching Efficiency")
    ax.set_xlabel("Global Batch Size")

    l = ax.legend(loc='lower center', ncols=2, bbox_to_anchor=(0.5, 1), prop={'size': 9}, columnspacing=0.8)
    if model == "GPT":
        l.get_texts()[0].set_text("MLM+DS")
        l.get_texts()[1].set_text("DynaPipe")
    else:
        l.get_texts()[0].set_text("MLM+DS (Encoder)")
        l.get_texts()[1].set_text("MLM+DS (Decoder)")
        l.get_texts()[2].set_text("DynaPipe (Encoder)")
        l.get_texts()[3].set_text("DynaPipe (Decoder)")

    for item in (ax.get_xticklabels() + ax.get_yticklabels()):
        item.set_fontsize(12)
    for item in [ax.title, ax.xaxis.label, ax.yaxis.label]:
        item.set_fontsize(12)
    plt.setp(ax.get_legend().get_texts(), fontsize='12') # for legend text
    plt.setp(ax.get_legend().get_title(), fontsize='12') # for legend title

    subfig = "a" if model == "GPT" else "b"
    plt.savefig(os.path.join(args.out_dir, f"fig14_{subfig}_right.pdf"), bbox_inches='tight')